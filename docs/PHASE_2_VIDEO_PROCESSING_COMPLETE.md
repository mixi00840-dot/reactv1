# Phase 2: Video Processing & Transcoding Pipeline - COMPLETE

## Overview
Production-ready video processing pipeline with FFmpeg-based transcoding, BullMQ job queue, multi-resolution output, HLS streaming, thumbnail generation, and distributed worker architecture.

## âœ… Completed Components (1,577 lines)

### 1. TranscodeJob Model (`TranscodeJob.js` - 402 lines)

**Purpose:** Track video processing jobs with detailed task management and output tracking.

**Key Features:**
- **Job States:** `pending` â†’ `queued` â†’ `processing` â†’ `completed`/`failed`/`cancelled`
- **Priority Queue:** 1-10 scale (higher = more important)
- **Task Management:** Multiple tasks per job (transcode, thumbnail, HLS, DASH, audio_extract, preview)
- **Progress Tracking:** Overall + per-task progress (0-100%)
- **Worker Management:** workerId, hostname, heartbeat tracking
- **Output Tracking:** Multiple quality outputs with metadata
- **Error Recovery:** Retry logic with max retry limits
- **Cost Estimation:** Compute, storage, bandwidth tracking

**Schema:**
```javascript
{
  jobId: String (unique, "job_timestamp_random"),
  contentId: ObjectId (Content ref),
  userId: ObjectId (User ref),
  status: Enum[pending, queued, processing, completed, failed, cancelled],
  priority: Number (1-10, default 5),
  
  sourceFile: {
    url, key, size, duration, width, height, fps, codec, bitrate, format
  },
  
  tasks: [{
    taskId: String,
    type: Enum[transcode, thumbnail, hls, dash, audio_extract, preview],
    status: Enum[pending, processing, completed, failed, skipped],
    config: Mixed,
    output: Mixed,
    progress: Number (0-100),
    startedAt, completedAt, error, retryCount
  }],
  
  outputs: [{
    quality: Enum[1080p, 720p, 480p, 360p, 240p, source],
    format: Enum[mp4, hls, dash],
    url, key, size, bitrate, width, height, duration, codec,
    manifestUrl, segmentCount, segmentDuration,
    status, completedAt
  }],
  
  thumbnails: [{
    url, key, width, height, timeOffset, size, format, isDefault, generatedAt
  }],
  
  animatedPreview: {
    url, key, duration, size, format, width, height, generatedAt
  },
  
  audioTrack: {
    url, key, duration, size, format, codec, bitrate, sampleRate, channels
  },
  
  progress: {
    overall: Number (0-100),
    currentTask, currentStep,
    tasksTotal, tasksCompleted, tasksFailed
  },
  
  worker: {
    workerId, hostname, startedAt, lastHeartbeat
  },
  
  errors: [{ task, error, stack, timestamp, retryable }],
  retryCount, maxRetries (default 3),
  
  estimatedCost, actualCost: { compute, storage, bandwidth, total }
}
```

**Indexes:**
- `{ status: 1, priority: -1, createdAt: 1 }` - Queue processing order
- `{ userId: 1, status: 1 }` - User's job history
- `{ 'worker.workerId': 1, status: 1 }` - Worker job tracking

**Methods:**
- `addTask(type, config)` - Add processing task
- `updateTaskProgress(taskId, progress, status)` - Update task
- `completeTask(taskId, output)` - Mark task complete
- `failTask(taskId, error)` - Mark task failed
- `start(workerId, hostname)` - Start processing
- `complete()` - Mark job complete
- `fail(error)` - Mark job failed
- `retry()` - Reset for retry (max 3 attempts)
- `heartbeat()` - Update worker heartbeat
- `addOutput(data)` - Add transcoded output
- `addThumbnail(data)` - Add thumbnail

**Static Methods:**
- `getNextJob()` - Get next pending job (priority + FIFO)
- `getStuckJobs()` - Find jobs with no heartbeat (>5 min)
- `getStats(timeRange)` - Job statistics by status
- `cleanOldJobs(daysOld)` - Delete old completed/failed jobs

---

### 2. VideoProcessor Service (`videoProcessor.js` - 431 lines)

**Purpose:** FFmpeg-based video processing engine with comprehensive transcoding capabilities.

**Encoding Presets:**
```javascript
{
  '1080p': { width: 1080, height: 1920, videoBitrate: '5000k', audioBitrate: '192k', fps: 30 },
  '720p':  { width: 720,  height: 1280, videoBitrate: '2500k', audioBitrate: '128k', fps: 30 },
  '480p':  { width: 480,  height: 854,  videoBitrate: '1000k', audioBitrate: '96k',  fps: 30 },
  '360p':  { width: 360,  height: 640,  videoBitrate: '600k',  audioBitrate: '96k',  fps: 30 },
  '240p':  { width: 240,  height: 426,  videoBitrate: '300k',  audioBitrate: '64k',  fps: 24 }
}
```

**Core Functions:**

**`getVideoMetadata(inputPath)`**
- Uses ffprobe to extract video/audio metadata
- Returns: duration, size, bitrate, format, video (codec, width, height, fps), audio (codec, sample rate, channels)

**`transcodeVideo(inputPath, outputPath, quality, onProgress)`**
- Transcode to specific quality preset
- Settings:
  - Video: H.264 (libx264), medium preset, CRF 23
  - Audio: AAC, stereo, 44.1kHz
  - Scaling: Force aspect ratio, pad to target resolution
  - Progressive download enabled (movflags +faststart)
- Progress callback with percentage

**`generateHLS(inputPath, outputDir, contentId)`**
- Create HLS (HTTP Live Streaming) manifest
- 6-second segments
- VOD playlist type
- Output: master.m3u8 + segment_*.ts files
- Returns: manifestUrl, segmentCount, segmentDuration

**`generateDASH(inputPath, outputDir)`**
- Create DASH (Dynamic Adaptive Streaming) manifest
- 6-second segments
- Template-based segments with timeline
- Output: manifest.mpd + segment files
- Returns: manifestUrl, segmentCount

**`extractThumbnails(inputPath, outputDir, count)`**
- Extract thumbnails at evenly spaced intervals
- Default: 5 thumbnails
- 720px width, maintains aspect ratio
- High quality JPEG (q:v 2)
- Returns: array of { path, filename, timeOffset, width }

**`generateAnimatedPreview(inputPath, outputPath, duration, startTime)`**
- Create short preview clip (default 3s)
- 360px width, 15fps for smaller size
- No audio, H.264 codec
- Returns: { path, duration }

**`extractAudio(inputPath, outputPath)`**
- Extract audio track from video
- MP3 format, 192kbps, 44.1kHz
- Returns: { path, duration, codec, bitrate, sampleRate, channels }

**`processVideo(inputPath, contentId, options)`**
- **Full pipeline orchestration**
- Steps:
  1. Get metadata (5% progress)
  2. Transcode to multiple qualities (10-70%)
  3. Generate HLS manifest (75%)
  4. Generate DASH manifest (80%) - optional
  5. Extract thumbnails (85%)
  6. Generate animated preview (90%)
  7. Extract audio track (95%)
  8. Complete (100%)
- Options:
  - `qualities`: ['720p', '480p', '360p'] - default
  - `generateHLS`: true/false
  - `generateDASH`: true/false
  - `thumbnailCount`: 5
  - `extractAudioTrack`: true/false
  - `generatePreview`: true/false
  - `onProgress`: callback(step, percent)
- Returns: { metadata, transcodes, hls, dash, thumbnails, audio, preview }

**`cleanup(paths)`**
- Delete temp files
- Error-tolerant cleanup

---

### 3. TranscodeQueue Service (`transcodeQueue.js` - 377 lines)

**Purpose:** BullMQ-based distributed job queue with Redis backend.

**Configuration:**
- Redis connection with ioredis
- Queue name: 'video-transcode'
- Default options:
  - Max 3 retry attempts
  - Exponential backoff (2s initial delay)
  - Keep last 100 completed jobs (24h retention)
  - Keep last 500 failed jobs

**Functions:**

**`addTranscodeJob(contentId, options)`**
- Create TranscodeJob record in database
- Configure tasks:
  - transcode: qualities array
  - thumbnail: count
  - hls: enabled flag
  - audio_extract: enabled flag
  - preview: duration, startTime
- Add to BullMQ queue with priority
- Update job status to 'queued'
- Returns: { transcodeJobId, queueJobId, status }

**`createTranscodeWorker(concurrency)`**
- Create BullMQ worker with specified concurrency (default 2)
- Worker ID: `worker_{hostname}_{pid}`
- Job processing flow:
  1. Load TranscodeJob and Content from database
  2. Start job tracking (workerId, heartbeat)
  3. Call videoProcessor.processVideo()
  4. Update task progress in real-time
  5. Save all outputs to TranscodeJob
  6. Update Content model with processed media
  7. Mark content as 'ready'
- Worker events: completed, failed, progress, error
- Rate limiting: 10 jobs per second max
- Returns: BullMQ Worker instance

**`getQueueStatus()`**
- Get current queue state
- Returns: { waiting, active, completed, failed, delayed, total }

**`cleanQueue(grace)`**
- Clean completed jobs older than grace period (seconds)
- Clean failed jobs older than 24x grace period

---

### 4. TranscodeController (`transcodeController.js` - 281 lines)

**Admin APIs for job management and monitoring**

**Endpoints:**

**`getTranscodeJobs()`** - GET /api/transcode/jobs
- List all transcode jobs with filtering
- Filters: status, userId
- Pagination: limit, skip
- Sort: sortBy, sortOrder
- Populates: userId (username, email), contentId (type, caption)
- Returns: jobs array + meta (total, hasMore)

**`getTranscodeJobById()`** - GET /api/transcode/jobs/:jobId
- Get single job with full details
- Populates: userId, contentId
- Returns: complete TranscodeJob object

**`getQueueStatus()`** - GET /api/transcode/queue/status
- Real-time queue metrics from BullMQ
- Database statistics for last 24h
- Returns: { queue: {...}, stats: {...} }

**`retryJob()`** - POST /api/transcode/jobs/:jobId/retry
- Retry failed job
- Checks: only failed jobs, max retries not exceeded
- Re-enqueues with higher priority (7)
- Returns: updated job

**`cancelJob()`** - POST /api/transcode/jobs/:jobId/cancel
- Cancel pending/processing job
- Cannot cancel completed jobs
- Returns: updated job

**`cleanOldJobs()`** - DELETE /api/transcode/jobs/old
- Delete completed/failed jobs older than N days (default 30)
- Also cleans BullMQ queue cache
- Returns: { deletedCount, daysOld }

**`getStuckJobs()`** - GET /api/transcode/jobs/stuck
- Find jobs with no heartbeat for >5 minutes
- Indicates crashed workers or network issues
- Returns: array of stuck jobs

**`resetStuckJobs()`** - POST /api/transcode/jobs/stuck/reset
- Reset stuck jobs for retry
- Attempts to retry each stuck job
- Returns: { resetCount, totalStuck }

**`getProcessingStats()`** - GET /api/transcode/stats
- Comprehensive statistics
- Aggregates:
  - Jobs by status (last N hours)
  - Average processing time
  - Min/max processing time
  - Success rate (completed / total)
  - Total completed/failed counts
- Returns: stats object

---

### 5. Transcode Routes (`transcode.js` - 26 lines)

**Admin-only routes at `/api/transcode`:**
```
GET    /queue/status             - Queue metrics
GET    /stats                    - Processing statistics

GET    /jobs                     - List all jobs (filtered)
GET    /jobs/stuck               - Find stuck jobs
GET    /jobs/:jobId              - Get job details
POST   /jobs/:jobId/retry        - Retry failed job
POST   /jobs/:jobId/cancel       - Cancel job

POST   /jobs/stuck/reset         - Reset all stuck jobs
DELETE /jobs/old                 - Clean old jobs
```

All routes require `protect` (JWT auth) + `adminOnly` middleware.

---

### 6. Transcode Worker (`transcodeWorker.js` - 59 lines)

**Standalone worker script for distributed processing**

**Usage:**
```bash
node src/workers/transcodeWorker.js [concurrency]
```

**Features:**
- Connects to MongoDB and Redis
- Creates BullMQ worker with specified concurrency
- Graceful shutdown on SIGINT/SIGTERM
- Error handling for uncaught exceptions
- Console logging with emojis for visibility

**Environment Variables:**
- `MONGODB_URI` - MongoDB connection string
- `REDIS_HOST` - Redis host (default: localhost)
- `REDIS_PORT` - Redis port (default: 6379)
- `REDIS_PASSWORD` - Redis password (optional)

**Deployment:**
- Run as background service (PM2, systemd, Docker)
- Scale horizontally: multiple workers across servers
- Auto-restart on crash
- Monitor with PM2 or Kubernetes

---

### 7. Integration Updates

**contentController.js**
- Added import: `addTranscodeJob` from transcodeQueue
- Updated `completeUpload()` to enqueue transcode jobs for videos
- Configuration:
  - Qualities: 720p, 480p, 360p (optimized for mobile)
  - HLS enabled, DASH disabled
  - 5 thumbnails
  - Audio extraction enabled
  - Priority: 5 (normal)
- Error handling: doesn't fail upload if queue fails

**app.js**
- Registered `/api/transcode` routes
- Admin-only access

**package.json**
- Added dependencies:
  - `fluent-ffmpeg@^2.1.2` - FFmpeg wrapper
  - `bullmq@^5.0.0` - Job queue
  - `ioredis@^5.3.2` - Redis client
- Added script: `worker:transcode` - Start worker

---

## ğŸ”„ Processing Flow

```
USER UPLOADS VIDEO (Phase 1)
          â†“
contentController.completeUpload()
          â†“
addTranscodeJob(contentId, options)
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TranscodeJob Created          â”‚
â”‚   - Tasks configured            â”‚
â”‚   - Status: pending â†’ queued    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BullMQ Queue (Redis)          â”‚
â”‚   - Priority-based ordering     â”‚
â”‚   - Retry logic                 â”‚
â”‚   - Rate limiting               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Worker Picks Job              â”‚
â”‚   - Sets workerId, heartbeat    â”‚
â”‚   - Status: queued â†’ processing â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   videoProcessor.processVideo() â”‚
â”‚   â”œâ”€ Get metadata (5%)          â”‚
â”‚   â”œâ”€ Transcode 720p (10-35%)    â”‚
â”‚   â”œâ”€ Transcode 480p (35-55%)    â”‚
â”‚   â”œâ”€ Transcode 360p (55-70%)    â”‚
â”‚   â”œâ”€ Generate HLS (75%)         â”‚
â”‚   â”œâ”€ Extract thumbnails (85%)   â”‚
â”‚   â”œâ”€ Generate preview (90%)     â”‚
â”‚   â””â”€ Extract audio (95%)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Save Results                  â”‚
â”‚   - Update TranscodeJob outputs â”‚
â”‚   - Update Content media        â”‚
â”‚   - Status: processing â†’ ready  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
VIDEO READY FOR STREAMING
```

---

## ğŸ“Š Output Structure

After processing, content has this file structure:
```
uploads/videos/{contentId}/
â”œâ”€â”€ 720p.mp4                    # 720p transcoded video
â”œâ”€â”€ 480p.mp4                    # 480p transcoded video
â”œâ”€â”€ 360p.mp4                    # 360p transcoded video
â”œâ”€â”€ audio.mp3                   # Extracted audio track
â”œâ”€â”€ preview.mp4                 # 3-second preview clip
â”œâ”€â”€ thumbnails/
â”‚   â”œâ”€â”€ thumb_1.jpg            # Thumbnail at 1/6 duration
â”‚   â”œâ”€â”€ thumb_2.jpg            # Thumbnail at 2/6 duration
â”‚   â”œâ”€â”€ thumb_3.jpg            # Thumbnail at 3/6 duration
â”‚   â”œâ”€â”€ thumb_4.jpg            # Thumbnail at 4/6 duration
â”‚   â””â”€â”€ thumb_5.jpg            # Thumbnail at 5/6 duration
â””â”€â”€ hls/
    â”œâ”€â”€ master.m3u8            # HLS master playlist
    â”œâ”€â”€ segment_001.ts         # HLS segment 1
    â”œâ”€â”€ segment_002.ts         # HLS segment 2
    â””â”€â”€ ...                    # More segments (6s each)
```

---

## ğŸ“¡ API Examples

### 1. Get Queue Status
```bash
GET /api/transcode/queue/status
Authorization: Bearer {admin_token}
```

**Response:**
```json
{
  "success": true,
  "data": {
    "queue": {
      "waiting": 5,
      "active": 2,
      "completed": 127,
      "failed": 3,
      "delayed": 0,
      "total": 137
    },
    "stats": {
      "totalJobs": 132,
      "byStatus": [
        { "_id": "completed", "count": 127, "avgProcessingTime": 45234, "totalCost": 12.45 },
        { "_id": "processing", "count": 2, "avgProcessingTime": null, "totalCost": 0 },
        { "_id": "failed", "count": 3, "avgProcessingTime": 12456, "totalCost": 0.5 }
      ],
      "timeRange": "24h"
    }
  }
}
```

### 2. List Transcode Jobs
```bash
GET /api/transcode/jobs?status=processing&limit=10
Authorization: Bearer {admin_token}
```

**Response:**
```json
{
  "success": true,
  "data": [
    {
      "_id": "672345abcdef123456789012",
      "jobId": "job_1730304000000_abc123xyz",
      "contentId": {
        "_id": "672345abcdef123456789000",
        "type": "video",
        "caption": "Amazing skateboarding trick!",
        "status": "processing"
      },
      "userId": {
        "_id": "672345abcdef123456789999",
        "username": "skater_pro",
        "fullName": "Alex Johnson",
        "email": "alex@example.com"
      },
      "status": "processing",
      "priority": 5,
      "progress": {
        "overall": 65,
        "currentTask": "task_1_transcode",
        "currentStep": "transcode_480p",
        "tasksTotal": 5,
        "tasksCompleted": 2,
        "tasksFailed": 0
      },
      "tasks": [
        {
          "taskId": "task_1_transcode",
          "type": "transcode",
          "status": "processing",
          "progress": 75,
          "startedAt": "2025-10-30T14:30:00Z"
        }
      ],
      "worker": {
        "workerId": "worker_server1_12345",
        "hostname": "server1.example.com",
        "lastHeartbeat": "2025-10-30T14:32:15Z"
      },
      "createdAt": "2025-10-30T14:25:00Z"
    }
  ],
  "meta": {
    "total": 1,
    "limit": 10,
    "skip": 0,
    "hasMore": false
  }
}
```

### 3. Get Processing Stats
```bash
GET /api/transcode/stats?timeRange=24
Authorization: Bearer {admin_token}
```

**Response:**
```json
{
  "success": true,
  "data": {
    "totalJobs": 132,
    "byStatus": [...],
    "timeRange": "24h",
    "processingTime": {
      "avgTime": 45234,      // milliseconds
      "minTime": 12456,
      "maxTime": 128900
    },
    "successRate": "97.69",  // percentage
    "completedCount": 127,
    "failedCount": 3
  }
}
```

### 4. Retry Failed Job
```bash
POST /api/transcode/jobs/672345abcdef123456789012/retry
Authorization: Bearer {admin_token}
```

**Response:**
```json
{
  "success": true,
  "message": "Job retry initiated",
  "data": {
    "_id": "672345abcdef123456789012",
    "status": "pending",
    "retryCount": 1
  }
}
```

---

## âš™ï¸ Configuration & Deployment

### FFmpeg Installation

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install ffmpeg
```

**macOS:**
```bash
brew install ffmpeg
```

**Windows:**
- Download from https://ffmpeg.org/download.html
- Add to PATH

**Docker:**
```dockerfile
FROM node:18
RUN apt-get update && apt-get install -y ffmpeg
```

### Redis Installation

**Ubuntu/Debian:**
```bash
sudo apt install redis-server
sudo systemctl start redis
```

**Docker:**
```bash
docker run -d -p 6379:6379 redis:7-alpine
```

### Environment Variables

**`.env` additions:**
```env
# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# Transcode Settings (optional)
TRANSCODE_CONCURRENCY=2
TRANSCODE_QUALITIES=720p,480p,360p
TRANSCODE_THUMBNAIL_COUNT=5
```

### Starting Workers

**Development (single worker):**
```bash
npm run worker:transcode
```

**Production (PM2):**
```bash
# Install PM2
npm install -g pm2

# Start worker with 2 concurrency
pm2 start src/workers/transcodeWorker.js --name transcode-worker -- 2

# Start multiple workers
pm2 start ecosystem.config.js

# Monitor
pm2 monit

# Auto-restart on system reboot
pm2 startup
pm2 save
```

**ecosystem.config.js:**
```javascript
module.exports = {
  apps: [{
    name: 'transcode-worker-1',
    script: './src/workers/transcodeWorker.js',
    args: '2',
    instances: 1,
    autorestart: true,
    watch: false,
    max_memory_restart: '2G',
    env: {
      NODE_ENV: 'production'
    }
  }]
};
```

**Docker Compose:**
```yaml
version: '3.8'
services:
  transcode-worker:
    build: .
    command: node src/workers/transcodeWorker.js 2
    environment:
      - MONGODB_URI=mongodb://mongo:27017/mixillo
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - mongo
      - redis
    volumes:
      - ./uploads:/app/uploads
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
```

---

## ğŸš€ Performance Considerations

**Optimizations Achieved:**
- âœ… Distributed processing with horizontal scaling
- âœ… Priority-based queue for important videos
- âœ… Retry logic with exponential backoff
- âœ… Worker heartbeat monitoring
- âœ… Progressive download enabled (faststart)
- âœ… Adaptive bitrate with multiple qualities
- âœ… HLS for optimal streaming performance
- âœ… Efficient thumbnail generation (evenly spaced)
- âœ… Rate limiting (10 jobs/sec) prevents overload
- âœ… Graceful worker shutdown

**Scaling Guidelines:**
- **Small (< 100 videos/day):** 1 worker, 2 concurrency
- **Medium (100-1000/day):** 2-3 workers, 2 concurrency each
- **Large (1000+/day):** 5+ workers, 2-4 concurrency, dedicated servers
- **Enterprise:** Kubernetes cluster with auto-scaling

**Resource Estimates (per video):**
- **CPU:** 100% utilization during transcoding
- **Memory:** 500MB-2GB (depends on resolution)
- **Time:** 30s-5min (varies by duration + resolution)
- **Storage:** 3-5x source file size (multiple qualities)

**Cost Optimization:**
- Use lower qualities for mobile-first content (480p, 360p)
- Skip 1080p if source is 720p or lower
- Disable DASH if only HLS is needed
- Reduce thumbnail count to 3 for faster processing
- Use AWS MediaConvert or similar managed service at scale

---

## ğŸ”’ Security & Reliability

**Security Features:**
- âœ… Admin-only access to transcode APIs
- âœ… Job ownership validation (userId tracking)
- âœ… File path sanitization
- âœ… Error message sanitization (no stack traces to users)
- âœ… Worker authentication via Redis

**Reliability Features:**
- âœ… Automatic retry (up to 3 attempts)
- âœ… Stuck job detection and recovery
- âœ… Heartbeat monitoring
- âœ… Error tracking and logging
- âœ… Job cleanup (30-day retention)
- âœ… Queue persistence (Redis AOF/RDB)

**Monitoring Recommendations:**
- Track queue depth (alert if > 100 waiting)
- Monitor processing time (alert if > 10min avg)
- Track failure rate (alert if > 5%)
- Monitor worker health (heartbeat checks)
- Track storage usage (alert at 80% capacity)
- Set up Redis persistence (AOF + RDB)

---

## ğŸ“¦ Dependencies Added

```json
{
  "fluent-ffmpeg": "^2.1.2",    // FFmpeg wrapper for Node.js
  "bullmq": "^5.0.0",            // Job queue with Redis
  "ioredis": "^5.3.2"            // Redis client
}
```

**Installation:**
```bash
npm install fluent-ffmpeg bullmq ioredis
```

---

## ğŸ¯ Testing the Pipeline

**1. Upload a video (Phase 1):**
```bash
# Initialize upload
POST /api/content/upload/initialize
{
  "fileName": "test_video.mp4",
  "fileSize": 10485760,
  "mimeType": "video/mp4",
  "uploadType": "video"
}

# Upload chunks...
# Complete upload...
```

**2. Check transcode job:**
```bash
# Get job status
GET /api/transcode/jobs?status=processing

# Get queue status
GET /api/transcode/queue/status
```

**3. Monitor worker:**
```bash
# Start worker
npm run worker:transcode

# Watch logs for progress
```

**4. Verify outputs:**
```bash
# Check content
GET /api/content/{contentId}

# Verify files created
ls uploads/videos/{contentId}/
```

---

## ğŸ“ˆ Next Steps (Phase 3)

Phase 2 provides the **video processing foundation**. The next critical phase will handle:

1. **Content Metrics Tracking** - Views, watch time, completion rate
2. **Engagement Scoring** - Likes, comments, shares, saves
3. **Real-time Analytics** - Event tracking for recommendation engine
4. **User Behavior Data** - Watch patterns for personalization

This data feeds into the recommendation engine (Phases 6-7) and trending system (Phase 8).

---

## âœ… Phase 2 Status: **COMPLETE**

**Total Code Delivered: 1,577 lines**

| Component | Lines | Purpose |
|-----------|-------|---------|
| TranscodeJob.js | 402 | Job tracking model |
| videoProcessor.js | 431 | FFmpeg processing engine |
| transcodeQueue.js | 377 | BullMQ queue & workers |
| transcodeController.js | 281 | Admin management APIs |
| transcode.js | 26 | Admin routes |
| transcodeWorker.js | 59 | Standalone worker script |
| **TOTAL** | **1,576** | **Production-ready** |

**Features Delivered:**
âœ… Multi-resolution transcoding (5 quality levels)
âœ… HLS adaptive streaming
âœ… Thumbnail generation (5 per video)
âœ… Animated preview generation
âœ… Audio track extraction
âœ… Distributed worker architecture
âœ… Job queue with priority + retry
âœ… Admin monitoring APIs
âœ… Worker health tracking
âœ… Error recovery & stuck job detection
âœ… Cost tracking & statistics

**Ready for Phase 3: Content Metrics & Engagement Tracking** ğŸš€
